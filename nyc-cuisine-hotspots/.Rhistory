cuisine_data <- cuisine_data %>%
mutate(boro_group = case_when(
boro == "Manhattan" ~ "Manhattan",
boro %in% c("Brooklyn", "Queens") ~ "Brooklyn/Queens",
boro == "Bronx" ~ "Bronx",
boro == "Staten Island" ~ "Staten Island",
TRUE ~ "Other"
))
all_results <- list()
cluster_offset <- 0
# Loop through each borough group
for (grp in unique(cuisine_data$boro_group)) {
eps <- eps_values[[grp]]
sub_data <- cuisine_data %>% filter(boro_group == grp)
if (nrow(sub_data) == 0) next
coords <- sub_data %>%
select(longitude, latitude) %>%
as.matrix()
db_result <- dbscan::dbscan(coords, eps = eps, minPts = minPts)
# Offset cluster IDs so they are unique across boroughs
sub_data <- sub_data %>%
mutate(cluster = ifelse(db_result$cluster == 0, 0, db_result$cluster + cluster_offset))
# Update offset for next borough
cluster_offset <- max(max(sub_data$cluster, na.rm = TRUE), cluster_offset)
all_results[[grp]] <- sub_data
}
final_data <- bind_rows(all_results)
return(final_data)
}
region_test_cuisine = "Chinese"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
run_dbscan_by_borough <- function(data, cuisine,
eps_values= c("Manhattan" = 0.004,
"Brooklyn/Queens" = 0.0078,
"Bronx" = 0.007,
"Staten Island" = 0.008),
min_floor = 4,
prop_factor = 0.015) {
# eps_values = named vector with borough groupings
# e.g., c("Manhattan" = 0.004, "Brooklyn/Queens" = 0.007, "Bronx" = 0.006, "Staten Island" = 0.008)
# Filter for chosen cuisine & clean coords
cuisine_data <- data %>%
filter(
cuisine_description == cuisine,
!is.na(latitude),
!is.na(longitude),
latitude != 0,
longitude != 0
)
# Dynamic minPts based on citywide restaurant count
total_count <- nrow(cuisine_data)
minPts <- max(min_floor, round(total_count * prop_factor))
# Group boroughs
cuisine_data <- cuisine_data %>%
mutate(boro_group = case_when(
boro == "Manhattan" ~ "Manhattan",
boro %in% c("Brooklyn", "Queens") ~ "Brooklyn/Queens",
boro == "Bronx" ~ "Bronx",
boro == "Staten Island" ~ "Staten Island",
TRUE ~ "Other"
))
all_results <- list()
cluster_offset <- 0
# Loop through each borough group
for (grp in unique(cuisine_data$boro_group)) {
eps <- eps_values[[grp]]
sub_data <- cuisine_data %>% filter(boro_group == grp)
if (nrow(sub_data) == 0) next
coords <- sub_data %>%
select(longitude, latitude) %>%
as.matrix()
db_result <- dbscan::dbscan(coords, eps = eps, minPts = minPts)
# Offset cluster IDs so they are unique across boroughs
sub_data <- sub_data %>%
mutate(cluster = ifelse(db_result$cluster == 0, 0, db_result$cluster + cluster_offset))
# Update offset for next borough
cluster_offset <- max(max(sub_data$cluster, na.rm = TRUE), cluster_offset)
all_results[[grp]] <- sub_data
}
final_data <- bind_rows(all_results)
return(final_data)
}
region_test_cuisine = "Chinese"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
eps_settings <- c(
"Manhattan" = 0.003,
"Brooklyn/Queens" = 0.008,
"Bronx" = 0.007,
"Staten Island" = 0.009
)
boro_test_cuisine = "Latin American"
test2_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = boro_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
map_dbscan_clusters(test2_clusters)
eps_settings <- c(
"Manhattan" = 0.004,
"Brooklyn/Queens" = 0.008,
"Bronx" = 0.007,
"Staten Island" = 0.009
)
boro_test_cuisine = "Latin American"
test2_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = boro_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
map_dbscan_clusters(test2_clusters)
eps_settings <- c(
"Manhattan" = 0.004,
"Brooklyn/Queens" = 0.008,
"Bronx" = 0.007,
"Staten Island" = 0.009
)
boro_test_cuisine = "Chinese"
test2_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = boro_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
map_dbscan_clusters(test2_clusters)
region_test_cuisine = "Chinese"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
eps_settings <- c(
"Manhattan" = 0.004,
"Brooklyn/Queens" = 0.008,
"Bronx" = 0.007,
"Staten Island" = 0.009
)
boro_test_cuisine = "Latin American"
test2_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = boro_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
map_dbscan_clusters(test2_clusters)
region_test_cuisine = "Chinese"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "African"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Russian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Bangladeshi"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Pakistani"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "African"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 2
prop_factor = 0.015
region_test_cuisine = "Ethiopian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 2,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 3,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 2,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
eps_settings_e <- c(
"Manhattan" = 0.006,
"Brooklyn/Queens" = 0.01,
"Bronx" = 0.009,
"Staten Island" = 0.011
)
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings_e,
min_floor = 2,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
eps_settings_e <- c(
"Manhattan" = 0.006,
"Brooklyn/Queens" = 0.01,
"Bronx" = 0.009,
"Staten Island" = 0.011
)
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings_e,
min_floor = 3,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Ethiopian"
eps_settings_e <- c(
"Manhattan" = 0.006,
"Brooklyn/Queens" = 0.01,
"Bronx" = 0.009,
"Staten Island" = 0.011
)
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings_e,
min_floor = 3,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "African"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 3,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "African"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
min_floor = 5,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "Chinese"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
region_test_cuisine = "African"
region_test_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = region_test_cuisine,
eps_values = eps_settings,
prop_factor = 0.015
)
region_test_hulls <- make_hotspot_polygons(region_test_clusters)
map_cluster_polygons(region_test_hulls)
calc_cluster_concentration <- function(clustered_data) {
# Filter out noise (cluster 0) and NA
clustered_data <- clustered_data %>%
filter(!is.na(cluster), cluster != 0)
total <- nrow(clustered_data)
if (total == 0) {
return(data.frame(
pct_in_clusters = 0,
largest_cluster_share = 0,
entropy = NA
))
}
# Calculate cluster proportions
cluster_props <- clustered_data %>%
count(cluster) %>%
mutate(prop = n / total)
# % in clusters (non-noise points relative to ALL restaurants for this cuisine)
pct_in_clusters <- total / nrow(clustered_data %>% bind_rows(
clustered_data, # all clustered points
clustered_data %>% filter(cluster == 0) # noise points
))
# Largest cluster share
largest_cluster_share <- max(cluster_props$prop)
# Shannon entropy
entropy <- -sum(cluster_props$prop * log(cluster_props$prop))
# Normalize entropy to [0, 1] range based on number of clusters
if (nrow(cluster_props) > 1) {
entropy <- entropy / log(nrow(cluster_props))
} else {
entropy <- 0 # only one cluster → zero entropy
}
return(data.frame(
pct_in_clusters = pct_in_clusters,
largest_cluster_share = largest_cluster_share,
entropy = entropy
))
}
calc_cluster_concentration(clusters_chinese)
calc_cluster_concentration(region_test_clusters)
conc_score_cuisine = "African"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Italian"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Russian"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Afghan"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Chinese"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Russian"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Japanese"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Peruvian"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Afghan"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
calc_cluster_concentration <- function(clustered_data) {
# Keep all rows with a cluster label (0 = noise)
df <- clustered_data %>% filter(!is.na(cluster))
N  <- nrow(df)
if (N == 0) {
return(tibble(
pct_in_clusters       = 0,
largest_cluster_share = 0,
entropy               = 0,
n_clusters            = 0,
pct_noise             = 1
))
}
# Counts
noise_n <- sum(df$cluster == 0, na.rm = TRUE)
clust_tbl <- df %>% filter(cluster != 0) %>% count(cluster, name = "n")
n_clusters <- nrow(clust_tbl)
# Metrics
pct_in_clusters <- (N - noise_n) / N
largest_cluster_share <- if (n_clusters > 0) max(clust_tbl$n) / N else 0
# Proportions including noise as its own bin
props <- c(clust_tbl$n, if (noise_n > 0) noise_n else NULL) / N
# Shannon entropy (normalized). If only one non-empty bin, define as 0.
H  <- -sum(props * log(props))
m  <- length(props)
Hn <- if (m <= 1) 0 else H / log(m)
tibble(
pct_in_clusters       = pct_in_clusters,
largest_cluster_share = largest_cluster_share,
entropy               = Hn,
n_clusters            = n_clusters,
pct_noise             = noise_n / N
)
}
conc_score_cuisine = "Afghan"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
conc_score_cuisine = "Chinese"
conc_clusters <- run_dbscan_by_borough(
data = restaurants_unique,
cuisine = conc_score_cuisine,
)
calc_cluster_concentration(conc_clusters)
